[core]
# The home folder for Airflow, default is ~/airflow
dags_folder = /usr/local/airflow/dags

# The folder where airflow should store its log files
# This path must be absolute
base_log_folder = /usr/local/airflow/logs

# The executor class that airflow should use. Choices include SequentialExecutor, LocalExecutor, CeleryExecutor, DaskExecutor, KubernetesExecutor, etc.
executor = SequentialExecutor

# The SqlAlchemy connection string to the metadata database.
# Sqlite is used by default, but you can also use other databases like PostgreSQL, MySQL, etc.
# Replace the following line with your actual database connection string.
sql_alchemy_conn = sqlite:////absolute/path/to/airflow.db

# The number of workers to run simultaneously in the LocalExecutor
local_task_job_timeout = 30

[webserver]
# The base url of your Airflow installation, e.g. http://localhost:8080
base_url = http://localhost:8080

# The port on which to run the web server
web_server_port =8080